{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7aeaff6-74ad-4c7e-99dc-ef65c3146bbf",
   "metadata": {},
   "source": [
    "# Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b6433f-cff7-4776-91d2-ffc21cee43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import joblib\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffcff27-c306-4bec-8c97-7dbe6dbd4961",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0a838e-7311-4f81-9cc2-7b9e8ef1b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this accordingly\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "dataset_dir = f\"{project_path}/scicite_preprocessed\"\n",
    "dataset = \"selected-features\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00321b-7a8c-4234-9db9-c7e649dd9355",
   "metadata": {},
   "source": [
    "## 1. Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435fdbbf-06b9-4eb6-be18-5f8980a4ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_df = pd.read_json(f\"{dataset_dir}/train_background.jsonl\", lines=True)\n",
    "method_df = pd.read_json(f\"{dataset_dir}/train_method.jsonl\", lines=True)\n",
    "result_df = pd.read_json(f\"{dataset_dir}/train_result.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac257502-7fe9-4bea-93c6-a9ff0a10db1a",
   "metadata": {},
   "source": [
    "## 2. Create BM25, Semantic and Hybrid Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40ec8782-4669-4de6-bdc2-3887b160b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticRetriever:\n",
    "    def __init__(self, documents, paper_ids, model_name=\"allenai/scibert_scivocab_uncased\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        \"\"\"\n",
    "        A Semantic Retriever using SciBERT embeddings for short documents (citations).\n",
    "        Stores document-paper_id pairs for retrieval.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "\n",
    "        # Load SciBERT tokenizer & model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device).eval()\n",
    "\n",
    "        # Store (document, paper_id) pairs\n",
    "        self.documents = documents\n",
    "        self.paper_ids = paper_ids\n",
    "        self.embeddings = self.embed_documents(documents)\n",
    "\n",
    "    def embed_text(self, text, max_length=512):\n",
    "        \"\"\" Converts text into SciBERT embeddings. \"\"\"\n",
    "        tokens = self.tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokens)\n",
    "        return outputs.last_hidden_state[:, 0, :].squeeze(0).cpu().numpy()  # [CLS] token\n",
    "\n",
    "    def embed_documents(self, documents):\n",
    "        \"\"\" Embeds all short documents using SciBERT. \"\"\"\n",
    "        return np.array([self.embed_text(doc) for doc in documents])\n",
    "\n",
    "    def retrieve(self, query, top_k=3):\n",
    "        \"\"\" Retrieves the most relevant documents along with their paper IDs. \"\"\"\n",
    "        query_embedding = self.embed_text(query).reshape(1, -1)\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_k:][::-1]  # Get top-k sorted indices\n",
    "        return [(self.documents[i], self.paper_ids[i]) for i in top_indices]\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, documents, paper_ids):\n",
    "        \n",
    "        self.documents = documents\n",
    "        self.paper_ids = paper_ids\n",
    "        \n",
    "        self.tokenized_docs = [word_tokenize(doc.lower()) for doc in self.documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_docs)\n",
    "\n",
    "        ################################\n",
    "        # Your code ends here\n",
    "        ################################\n",
    "    \n",
    "    def retrieve(self, query, top_k=3):\n",
    "        \n",
    "        query_tokens = word_tokenize(query.lower())\n",
    "        scores = self.bm25.get_scores(query_tokens)\n",
    "        top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "\n",
    "        return [(self.documents[i], self.paper_ids[i]) for i in top_indices]\n",
    "\n",
    "class HybridRetriever:\n",
    "    def __init__(self, documents, paper_ids, bm25_weight=0.5, semantic_weight=0.5, model_name=\"allenai/scibert_scivocab_uncased\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        \"\"\"\n",
    "        HybridRetriever: Combines BM25 and Semantic Retrieval.\n",
    "        Uses a weighted combination of both scores to retrieve documents.\n",
    "        \"\"\"\n",
    "        self.bm25_weight = bm25_weight\n",
    "        self.semantic_weight = semantic_weight\n",
    "\n",
    "        self.documents = documents\n",
    "        self.paper_ids = paper_ids\n",
    "        \n",
    "        # BM25\n",
    "        self.tokenized_docs = [word_tokenize(doc.lower()) for doc in self.documents]\n",
    "        self.bm25 = BM25Okapi(self.tokenized_docs)\n",
    "\n",
    "        # Semantic\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device).eval()\n",
    "        self.embeddings = self.embed_documents(documents)\n",
    "    \n",
    "    def embed_text(self, text, max_length=512):\n",
    "        \"\"\" Converts text into SciBERT embeddings. \"\"\"\n",
    "        tokens = self.tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokens)\n",
    "        return outputs.last_hidden_state[:, 0, :].squeeze(0).cpu().numpy()  # [CLS] token\n",
    "\n",
    "    def embed_documents(self, documents):\n",
    "        \"\"\" Embeds all short documents using SciBERT. \"\"\"\n",
    "        return np.array([self.embed_text(doc) for doc in documents])\n",
    "    \n",
    "    def retrieve(self, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Retrieves the top_k most relevant documents using a combination of BM25 and semantic scores.\n",
    "        \"\"\"\n",
    "        # BM25\n",
    "        query_tokens = word_tokenize(query.lower())\n",
    "        bm25_scores = self.bm25.get_scores(query_tokens)\n",
    "\n",
    "        # Semantic\n",
    "        query_embedding = self.embed_text(query).reshape(1, -1)\n",
    "        semantic_scores = cosine_similarity(query_embedding, self.embeddings).flatten()\n",
    "        \n",
    "        # Weighted combination\n",
    "        combined_scores = (self.bm25_weight * bm25_scores) + (self.semantic_weight * semantic_scores)\n",
    "\n",
    "        # Retrieve top-k sentences\n",
    "        top_indices = sorted(range(len(combined_scores)), key=lambda i: combined_scores[i], reverse=True)[:top_k]\n",
    "        \n",
    "        return [(self.documents[i], self.paper_ids[i]) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "790ba1b1-086b-4d37-b496-e21057d6671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract citations & paper IDs for each label\n",
    "method_docs, method_ids = method_df[\"string\"].tolist(), method_df[\"id\"].tolist()\n",
    "background_docs, background_ids = background_df[\"string\"].tolist(), background_df[\"id\"].tolist()\n",
    "result_docs, result_ids = result_df[\"string\"].tolist(), result_df[\"id\"].tolist()\n",
    "\n",
    "# Initialize retrievers for each category\n",
    "bm_method_retriever = BM25Retriever(method_docs, method_ids)\n",
    "bm_background_retriever = BM25Retriever(background_docs, background_ids)\n",
    "bm_result_retriever = BM25Retriever(result_docs, result_ids)\n",
    "\n",
    "sem_method_retriever = SemanticRetriever(method_docs, method_ids)\n",
    "sem_background_retriever = SemanticRetriever(background_docs, background_ids)\n",
    "sem_result_retriever = SemanticRetriever(result_docs, result_ids)\n",
    "\n",
    "hyb_method_retriever = HybridRetriever(method_docs, method_ids)\n",
    "hyb_background_retriever = HybridRetriever(background_docs, background_ids)\n",
    "hyb_result_retriever = HybridRetriever(result_docs, result_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74a726-8550-48ab-9192-7631e51d718a",
   "metadata": {},
   "source": [
    "## 4. Classify input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f7c7693-4384-45c3-9ba9-d44f446869cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citeEnd</th>\n",
       "      <th>citeStart</th>\n",
       "      <th>excerpt_index</th>\n",
       "      <th>source_acronym</th>\n",
       "      <th>source_acronymParen</th>\n",
       "      <th>source_andPhrase</th>\n",
       "      <th>source_etAlPhrase</th>\n",
       "      <th>source_explicit</th>\n",
       "      <th>source_properNoun</th>\n",
       "      <th>isKeyCitation_False</th>\n",
       "      <th>...</th>\n",
       "      <th>zhu et al_tfidf</th>\n",
       "      <th>zimbabwe_tfidf</th>\n",
       "      <th>zinc_tfidf</th>\n",
       "      <th>zinc finger_tfidf</th>\n",
       "      <th>zn_tfidf</th>\n",
       "      <th>zone_tfidf</th>\n",
       "      <th>äì_tfidf</th>\n",
       "      <th>ðþ_tfidf</th>\n",
       "      <th>βarr_tfidf</th>\n",
       "      <th>μm_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>120.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 10016 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     citeEnd  citeStart  excerpt_index  source_acronym  source_acronymParen  \\\n",
       "233    120.0      112.0              1             0.0                  0.0   \n",
       "\n",
       "     source_andPhrase  source_etAlPhrase  source_explicit  source_properNoun  \\\n",
       "233               0.0                0.0              1.0                0.0   \n",
       "\n",
       "     isKeyCitation_False  ...  zhu et al_tfidf  zimbabwe_tfidf  zinc_tfidf  \\\n",
       "233                  1.0  ...              0.0             0.0         0.0   \n",
       "\n",
       "     zinc finger_tfidf  zn_tfidf  zone_tfidf  äì_tfidf  ðþ_tfidf  βarr_tfidf  \\\n",
       "233                0.0       0.0         0.0       0.0       0.0         0.0   \n",
       "\n",
       "     μm_tfidf  \n",
       "233       0.0  \n",
       "\n",
       "[1 rows x 10016 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>citeEnd</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>citeStart</th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "      <th>citingPaperId</th>\n",
       "      <th>citedPaperId</th>\n",
       "      <th>isKeyCitation</th>\n",
       "      <th>id</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>excerpt_index</th>\n",
       "      <th>label2</th>\n",
       "      <th>label_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>explicit</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Plasma cell biology</td>\n",
       "      <td>112.0</td>\n",
       "      <td>When lymph node follicular B-cells encounter a...</td>\n",
       "      <td>background</td>\n",
       "      <td>3b6fce00a747ffaa22a67b334f733c9f40bff561</td>\n",
       "      <td>846066f8b6cefd92169d860e14bf60d9167d072a</td>\n",
       "      <td>False</td>\n",
       "      <td>3b6fce00a747ffaa22a67b334f733c9f40bff561&gt;84606...</td>\n",
       "      <td>3b6fce00a747ffaa22a67b334f733c9f40bff561&gt;84606...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source  citeEnd          sectionName  citeStart  \\\n",
       "233  explicit    120.0  Plasma cell biology      112.0   \n",
       "\n",
       "                                                string       label  \\\n",
       "233  When lymph node follicular B-cells encounter a...  background   \n",
       "\n",
       "                                citingPaperId  \\\n",
       "233  3b6fce00a747ffaa22a67b334f733c9f40bff561   \n",
       "\n",
       "                                 citedPaperId  isKeyCitation  \\\n",
       "233  846066f8b6cefd92169d860e14bf60d9167d072a          False   \n",
       "\n",
       "                                                    id  \\\n",
       "233  3b6fce00a747ffaa22a67b334f733c9f40bff561>84606...   \n",
       "\n",
       "                                             unique_id  excerpt_index label2  \\\n",
       "233  3b6fce00a747ffaa22a67b334f733c9f40bff561>84606...              1    NaN   \n",
       "\n",
       "     label_confidence  \n",
       "233               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ori_test_df = pd.read_json(f\"{project_path}/scicite/test.jsonl\", lines=True)\n",
    "test_df = pd.read_csv(f\"{dataset_dir}/test-{dataset}.csv\")\n",
    "\n",
    "sample_test_df = test_df.sample(n=1, random_state=42)  # Random 3 rows\n",
    "X_test = sample_test_df.drop(columns=['label'])\n",
    "y_test = sample_test_df[\"label\"]\n",
    "\n",
    "# Select the same indices from the original test dataset\n",
    "ori_sample_test_df = ori_test_df.loc[sample_test_df.index]\n",
    "\n",
    "# Display the selected rows\n",
    "display(X_test)\n",
    "display(ori_sample_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d42954b3-80dd-4ab8-9f90-53a8da5960ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions vs True Labels:\n",
      "   Predicted  True\n",
      "0          0     0\n"
     ]
    }
   ],
   "source": [
    "# Load the classifier \n",
    "classifier = joblib.load(f\"{dataset_dir}/selected_classifier.pkl\")\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "\n",
    "# Print predictions and true labels\n",
    "print(\"Predictions vs True Labels:\")\n",
    "df_comparison = pd.DataFrame({\"Predicted\": pred, \"True\": y_test.values})\n",
    "print(df_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe433d25-3332-4f36-b58d-a3297edd293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: When lymph node follicular B-cells encounter antigen and T-cell help, this results in germinal center formation (62, 74).\n",
      "\n",
      "Predicted Label: background\n",
      "\n",
      "\n",
      "BM Retriever:\n",
      "\n",
      "Document: reported to be 3% by another study, lymphadenopathy was not among the clinical symptoms in the south of Iran.([23]) In previous studies, the lymph node metastasis was not reported in this area.\n",
      "Paper ID: 4a254161278510ddcd1e386d71c8e97ca572774f>d81ce287e36056710a5d77ed74245a6cbe89824e\n",
      "--------------------------------------------------\n",
      "Document: Untreated infection results in the progressive depletion of the helper T-cell population, and the resulting immunodeficiency leads to death by opportunistic infection (Thompson et al. (2012)).\n",
      "Paper ID: 957bf5cc5e797dd078bbea21cb6cb17d41026dcc>8b4b51fffb43ad57ac9aa8e5deeac45f6356e015\n",
      "--------------------------------------------------\n",
      "Document: ankle-link antigen (ALA) with ankle links (Goodyear and Richardson, 1999), and the tip-link antigen (TLA) with tip and kinocilial links (Goodyear and Richardson, 2003).\n",
      "Paper ID: b38a9735318cf86573a8c3bbdd58747527e6d3b1>f05330eb7b43478aca0790b843a4d6ffb3043a94\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Semantic Retriever:\n",
      "\n",
      "Document: When IL-17 is blocked during a high-dose challenge, neutrophil recruitment is hindered, and this may alter subsequent development of inflammation (55).\n",
      "Paper ID: 998b2e755456700a4fc07c6dd1f32d243899d09f>c5162ef5c68848eba50818b64f7a783f1cde4c73\n",
      "--------------------------------------------------\n",
      "Document: Untreated infection results in the progressive depletion of the helper T-cell population, and the resulting immunodeficiency leads to death by opportunistic infection (Thompson et al. (2012)).\n",
      "Paper ID: 957bf5cc5e797dd078bbea21cb6cb17d41026dcc>8b4b51fffb43ad57ac9aa8e5deeac45f6356e015\n",
      "--------------------------------------------------\n",
      "Document: Antigen receptor signaling during clonal expansion likely drives down Bcl-2 levels and hyper-induce Mcl-1 in responding CD8 T cells (Dunkle et al., 2011; Opferman et al., 2003).\n",
      "Paper ID: e3450e8ca6d743f04a1ad41297ab59eeb82299b4>b5fcda6fd9a47d7ef14b8e3e8c80c00fde1b990a\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Hybrid Retriever:\n",
      "\n",
      "Document: reported to be 3% by another study, lymphadenopathy was not among the clinical symptoms in the south of Iran.([23]) In previous studies, the lymph node metastasis was not reported in this area.\n",
      "Paper ID: 4a254161278510ddcd1e386d71c8e97ca572774f>d81ce287e36056710a5d77ed74245a6cbe89824e\n",
      "--------------------------------------------------\n",
      "Document: Untreated infection results in the progressive depletion of the helper T-cell population, and the resulting immunodeficiency leads to death by opportunistic infection (Thompson et al. (2012)).\n",
      "Paper ID: 957bf5cc5e797dd078bbea21cb6cb17d41026dcc>8b4b51fffb43ad57ac9aa8e5deeac45f6356e015\n",
      "--------------------------------------------------\n",
      "Document: ankle-link antigen (ALA) with ankle links (Goodyear and Richardson, 1999), and the tip-link antigen (TLA) with tip and kinocilial links (Goodyear and Richardson, 2003).\n",
      "Paper ID: b38a9735318cf86573a8c3bbdd58747527e6d3b1>f05330eb7b43478aca0790b843a4d6ffb3043a94\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize retrievers for each label\n",
    "label_encoder = joblib.load(f\"{dataset_dir}/label_encoder.pkl\")\n",
    "label_strings = label_encoder.inverse_transform(pred)\n",
    "\n",
    "bm_retrievers = {\n",
    "    \"background\": bm_background_retriever,\n",
    "    \"method\": bm_method_retriever,\n",
    "    \"result\": bm_result_retriever\n",
    "}\n",
    "\n",
    "sem_retrievers = {\n",
    "    \"background\": sem_background_retriever,\n",
    "    \"method\": sem_method_retriever,\n",
    "    \"result\": sem_result_retriever\n",
    "}\n",
    "\n",
    "hyb_retrievers = {\n",
    "    \"background\": hyb_background_retriever,\n",
    "    \"method\": hyb_method_retriever,\n",
    "    \"result\": hyb_result_retriever\n",
    "}\n",
    "\n",
    "# Retrieve relevant documents based on predicted labels\n",
    "retrieved_docs = []\n",
    "\n",
    "for idx, label in enumerate(label_strings):\n",
    "    query = ori_sample_test_df.iloc[idx][\"string\"]\n",
    "    bm_retriever = bm_retrievers.get(label)\n",
    "    sem_retriever = sem_retrievers.get(label)\n",
    "    hyb_retriever = hyb_retrievers.get(label)     \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    print(f\"Predicted Label: {label}\\n\\n\")\n",
    "\n",
    "    print(f\"BM Retriever:\\n\")\n",
    "    relevant_docs = bm_retriever.retrieve(query, top_k=3)\n",
    "    for doc, paper_id in relevant_docs:\n",
    "        print(f\"Document: {doc}\")\n",
    "        print(f\"Paper ID: {paper_id}\")\n",
    "        print(\"-\" * 50)\n",
    "        retrieved_docs.append({\"Predicted Label\": label, \"Document\": doc, \"Paper ID\": paper_id})\n",
    "\n",
    "    print(f\"\\n\\nSemantic Retriever:\\n\")\n",
    "    relevant_docs = sem_retriever.retrieve(query, top_k=3)\n",
    "    for doc, paper_id in relevant_docs:\n",
    "        print(f\"Document: {doc}\")\n",
    "        print(f\"Paper ID: {paper_id}\")\n",
    "        print(\"-\" * 50)\n",
    "        retrieved_docs.append({\"Predicted Label\": label, \"Document\": doc, \"Paper ID\": paper_id})\n",
    "\n",
    "    print(f\"\\n\\nHybrid Retriever:\\n\")\n",
    "    relevant_docs = hyb_retriever.retrieve(query, top_k=3)\n",
    "    for doc, paper_id in relevant_docs:\n",
    "        print(f\"Document: {doc}\")\n",
    "        print(f\"Paper ID: {paper_id}\")\n",
    "        print(\"-\" * 50)\n",
    "        retrieved_docs.append({\"Predicted Label\": label, \"Document\": doc, \"Paper ID\": paper_id})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b8689-7862-4dc0-a4ff-03cd00e48c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
